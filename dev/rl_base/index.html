<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>RLBase · ReinforcementLearning.jl</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-149861753-1', 'auto');
ga('send', 'pageview', {'page': location.pathname + location.search + location.hash});
</script><link rel="canonical" href="https://juliareinforcementlearning.github.io/ReinforcementLearning.jl/latest/rl_base/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../assets/custom.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="ReinforcementLearning.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">ReinforcementLearning.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../a_quick_example/">A Quick Example</a></li><li><span class="tocitem">Manual</span><ul><li class="is-active"><a class="tocitem" href>RLBase</a><ul class="internal"><li><a class="tocitem" href="#General-1"><span>General</span></a></li><li><a class="tocitem" href="#Agent-1"><span>Agent</span></a></li><li><a class="tocitem" href="#Policy-1"><span>Policy</span></a></li><li><a class="tocitem" href="#Learner-1"><span>Learner</span></a></li><li><a class="tocitem" href="#Approximator-1"><span>Approximator</span></a></li><li><a class="tocitem" href="#Explorer-1"><span>Explorer</span></a></li><li><a class="tocitem" href="#EnvironmentModel-1"><span>EnvironmentModel</span></a></li><li><a class="tocitem" href="#Environment-1"><span>Environment</span></a></li><li><a class="tocitem" href="#Preprocessor-1"><span>Preprocessor</span></a></li><li><a class="tocitem" href="#Observation-1"><span>Observation</span></a></li><li><a class="tocitem" href="#Trajectory-1"><span>Trajectory</span></a></li><li><a class="tocitem" href="#Space-1"><span>Space</span></a></li></ul></li><li><a class="tocitem" href="../rl_core/">RLCore</a></li><li><a class="tocitem" href="../rl_envs/">RLEnvs</a></li><li><a class="tocitem" href="../rl_zoo/">RLZoo</a></li></ul></li><li><a class="tocitem" href="../tips_for_developers/">Tips for Developers</a></li><li><span class="tocitem">Experiments</span><ul><li><a class="tocitem" href="../experiments/atari_dqn/">Play Atari Games with DQN</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href>RLBase</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>RLBase</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/master/docs/src/rl_base.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="ReinforcementLearningBase.jl-1"><a class="docs-heading-anchor" href="#ReinforcementLearningBase.jl-1">ReinforcementLearningBase.jl</a><a class="docs-heading-anchor-permalink" href="#ReinforcementLearningBase.jl-1" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.RLBase" href="#ReinforcementLearningBase.RLBase"><code>ReinforcementLearningBase.RLBase</code></a> — <span class="docstring-category">Module</span></header><section><div><p><a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningBase.jl">ReinforcementLearningBase.jl</a> (<strong>RLBase</strong>) provides some common constants, traits, abstractions and interfaces in developing reinforcement learning algorithms in  Julia. From the concept level, they can be organized in the following parts:</p><ul><li><a href="#General-1">General</a></li><li><a href="#Agent-1">Agent</a><ul><li><a href="#Policy-1">Policy</a><ul><li><a href="#Learner-1">Learner</a><ul><li><a href="#Approximator-1">Approximator</a></li></ul></li><li><a href="#Explorer-1">Explorer</a></li></ul></li></ul></li><li><a href="#EnvironmentModel-1">EnvironmentModel</a></li><li><a href="#Environment-1">Environment</a><ul><li><a href="#Preprocessor-1">Preprocessor</a></li><li><a href="#Observation-1">Observation</a></li><li><a href="#Trajectory-1">Trajectory</a></li><li><a href="#Space-1">Space</a></li></ul></li></ul></div></section></article><h2 id="General-1"><a class="docs-heading-anchor" href="#General-1">General</a><a class="docs-heading-anchor-permalink" href="#General-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractStage" href="#ReinforcementLearningBase.AbstractStage"><code>ReinforcementLearningBase.AbstractStage</code></a> — <span class="docstring-category">Type</span></header><section><div><p>In the simplest case, we just need to run <code>env |&gt; observe |&gt; agent |&gt; env</code> repeatly. But usually we would also like to control when/how to update the agent. So we defined the following stages for the help:</p><ul><li><code>PRE_EXPERIMENT_STAGE</code></li><li><code>PRE_EPISODE_STAGE</code></li><li><code>PRE_ACT_STAGE</code></li><li><code>POST_ACT_STAGE</code></li><li><code>POST_EPISODE_STAGE</code></li><li><code>POST_EXPERIMENT_STAGE</code></li></ul><pre><code class="language-none">                      +-----------------------------------------------------------+                      
                      |Episode                                                    |                      
                      |                                                           |                      
PRE_EXPERIMENT_STAGE  |            PRE_ACT_STAGE    POST_ACT_STAGE                | POST_EXPERIMENT_STAGE
         |            |                  |                |                       |          |           
         v            |        +-----+   v   +-------+    v   +-----+             |          v           
         ---------------------&gt;+ env +------&gt;+ agent +-------&gt;+ env +---&gt; ... -------&gt;......             
                      |  ^     +-----+  obs  +-------+ action +-----+          ^  |                      
                      |  |                                                     |  |                      
                      |  +--PRE_EPISODE_STAGE            POST_EPISODE_STAGE----+  |                      
                      |                                                           |                      
                      |                                                           |                      
                      +-----------------------------------------------------------+                      </code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L25">source</a></section></article><h2 id="Agent-1"><a class="docs-heading-anchor" href="#Agent-1">Agent</a><a class="docs-heading-anchor-permalink" href="#Agent-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractAgent" href="#ReinforcementLearningBase.AbstractAgent"><code>ReinforcementLearningBase.AbstractAgent</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">(agent::AbstractAgent)(obs) = agent(PRE_ACT_STAGE, obs) -&gt; action
(agent::AbstractAgent)(stage::AbstractStage, obs)</code></pre><p>An agent is a functional object which takes in an observation and returns an action. In different stages, the behavior may be different.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_role" href="#ReinforcementLearningBase.get_role"><code>ReinforcementLearningBase.get_role</code></a> — <span class="docstring-category">Function</span></header><section><div><p>return <a href="#ReinforcementLearningBase.DEFAULT_PLAYER"><code>DEFAULT_PLAYER</code></a> by default</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.DEFAULT_PLAYER" href="#ReinforcementLearningBase.DEFAULT_PLAYER"><code>ReinforcementLearningBase.DEFAULT_PLAYER</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Default player instance for all the environments</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><h2 id="Policy-1"><a class="docs-heading-anchor" href="#Policy-1">Policy</a><a class="docs-heading-anchor-permalink" href="#Policy-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractPolicy" href="#ReinforcementLearningBase.AbstractPolicy"><code>ReinforcementLearningBase.AbstractPolicy</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">(p::AbstractPolicy)(obs) = p(obs, ActionStyle(obs)) -&gt; action</code></pre><p>Similar to <a href="#ReinforcementLearningBase.AbstractAgent"><code>AbstractAgent</code></a>, a policy is aslo a functional object which defines how to generate action(s) given an observation of the environment. However, in the concept level, a policy is more lower and usually it doesn&#39;t need to care about how/when to interact with an environment.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.update!-Tuple{AbstractPolicy,Any}" href="#ReinforcementLearningBase.update!-Tuple{AbstractPolicy,Any}"><code>ReinforcementLearningBase.update!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">update!(p::AbstractPolicy, experience)</code></pre><p>Update the policy <code>p</code> with experience</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_prob-Tuple{AbstractPolicy,Any}" href="#ReinforcementLearningBase.get_prob-Tuple{AbstractPolicy,Any}"><code>ReinforcementLearningBase.get_prob</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_prob(p::AbstractPolicy, obs) = get_prob(p, obs, ActionStyle(obs))
get_prob(p::AbstractPolicy, obs, ::AbstractActionStyle)</code></pre><p>Get the probability distribution of actions from the policy <code>p</code> given an observation <code>obs</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_prob-Tuple{AbstractPolicy,Any,Any}" href="#ReinforcementLearningBase.get_prob-Tuple{AbstractPolicy,Any,Any}"><code>ReinforcementLearningBase.get_prob</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_prob(p::AbstractPolicy, obs, a) = get_prob(p, obs, ActionStyle(obs), a)</code></pre><p>Get the probability of to take action <code>a</code> from the policy <code>p</code> given an observation <code>obs</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_priority" href="#ReinforcementLearningBase.get_priority"><code>ReinforcementLearningBase.get_priority</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_priority(p::AbstractLearner, experience)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section><section><div><pre><code class="language-none">get_priority(p::AbstractPolicy, experience)</code></pre><p>Calculate the priority of the <code>experience</code> to policy <code>p</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><h2 id="Learner-1"><a class="docs-heading-anchor" href="#Learner-1">Learner</a><a class="docs-heading-anchor-permalink" href="#Learner-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractLearner" href="#ReinforcementLearningBase.AbstractLearner"><code>ReinforcementLearningBase.AbstractLearner</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">(learner::AbstractLearner)(obs)</code></pre><p>A learner is usually a wrapper around <a href="#ReinforcementLearningBase.AbstractApproximator"><code>AbstractApproximator</code></a>s. It defines the expected inputs and how to update inner approximators. From the concept level, it assumes that the necessary training data is  already cooked (usually by <a href="#ReinforcementLearningBase.AbstractPolicy"><code>AbstractPolicy</code></a> with the <a href="#ReinforcementLearningBase.extract_experience-Tuple{AbstractTrajectory,AbstractLearner}"><code>extract_experience</code></a> method).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.update!-Tuple{AbstractLearner,Any}" href="#ReinforcementLearningBase.update!-Tuple{AbstractLearner,Any}"><code>ReinforcementLearningBase.update!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">update!(learner::AbstractLearner, experience)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_priority-Tuple{AbstractLearner,Any}" href="#ReinforcementLearningBase.get_priority-Tuple{AbstractLearner,Any}"><code>ReinforcementLearningBase.get_priority</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_priority(p::AbstractLearner, experience)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.extract_experience-Tuple{AbstractTrajectory,AbstractLearner}" href="#ReinforcementLearningBase.extract_experience-Tuple{AbstractTrajectory,AbstractLearner}"><code>ReinforcementLearningBase.extract_experience</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">extract_experience(trajectory::AbstractTrajectory, learner::AbstractLearner)</code></pre><p>Extract necessary data from the <code>trajectory</code> given a <code>learner</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><h2 id="Approximator-1"><a class="docs-heading-anchor" href="#Approximator-1">Approximator</a><a class="docs-heading-anchor-permalink" href="#Approximator-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractApproximator" href="#ReinforcementLearningBase.AbstractApproximator"><code>ReinforcementLearningBase.AbstractApproximator</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">(app::AbstractApproximator)(obs) = app(get_state(obs))</code></pre><p>An approximator is a functional object for value estimation. It serves as a black box to provides an abstraction over different  kinds of approximate methods (for example DNN provided by Flux or Knet).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.batch_estimate" href="#ReinforcementLearningBase.batch_estimate"><code>ReinforcementLearningBase.batch_estimate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">batch_estimate(app::AbstractApproximator, states)</code></pre><p>The <code>states</code> is assume to be a batch of states</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.update!-Tuple{AbstractApproximator,Any}" href="#ReinforcementLearningBase.update!-Tuple{AbstractApproximator,Any}"><code>ReinforcementLearningBase.update!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">update!(a::AbstractApproximator, correction)</code></pre><p>Usually the <code>correction</code> is the gradient of inner parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.copyto!-Tuple{AbstractApproximator,AbstractApproximator}" href="#Base.copyto!-Tuple{AbstractApproximator,AbstractApproximator}"><code>Base.copyto!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Base.copyto!(dest::AbstractApproximator, src::AbstractApproximator)</code></pre><p>Copy the internal params from <code>src</code> approximator to <code>dest</code> approximator</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.ApproximatorStyle" href="#ReinforcementLearningBase.ApproximatorStyle"><code>ReinforcementLearningBase.ApproximatorStyle</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ApproximatorStyle(x::AbstractApproximator)</code></pre><p>Detect which kind of approximator it is</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.Q_APPROXIMATOR" href="#ReinforcementLearningBase.Q_APPROXIMATOR"><code>ReinforcementLearningBase.Q_APPROXIMATOR</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>For <code>Q_APPROXIMATOR</code>, we assume that the following methods are implemented:</p><ul><li><code>(Q::AbstractApproximator)(s, a)</code>, estimate the Q value.</li><li><code>(Q::AbstractApproximator)(s)</code>, estimate the Q value among all possible actions.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.V_APPROXIMATOR" href="#ReinforcementLearningBase.V_APPROXIMATOR"><code>ReinforcementLearningBase.V_APPROXIMATOR</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>For <code>V_APPROXIMATOR</code>, we assume that <code>(V::AbstractApproximator)(s)</code> is implemented.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.HYBRID_APPROXIMATOR" href="#ReinforcementLearningBase.HYBRID_APPROXIMATOR"><code>ReinforcementLearningBase.HYBRID_APPROXIMATOR</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>For <code>HYBRID_APPROXIMATOR</code>, the following methods are assumed to be implemented:</p><ul><li><code>(app::AbstractApproximator)(s, ::Val{:Q})</code>, estimate the action values of state <code>s</code>.</li><li><code>(app::AbstractApproximator)(s, ::Val{:V})</code>, estimate the state values.</li><li><code>(app::AbstractApproximator)(s, a)</code>, estimate state-action values.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L5">source</a></section></article><h2 id="Explorer-1"><a class="docs-heading-anchor" href="#Explorer-1">Explorer</a><a class="docs-heading-anchor-permalink" href="#Explorer-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractExplorer" href="#ReinforcementLearningBase.AbstractExplorer"><code>ReinforcementLearningBase.AbstractExplorer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">(p::AbstractExplorer)(x)
(p::AbstractExplorer)(x, mask)</code></pre><p>Define how to select an action based on action values.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.reset!-Tuple{AbstractExplorer}" href="#ReinforcementLearningBase.reset!-Tuple{AbstractExplorer}"><code>ReinforcementLearningBase.reset!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Reset the internal state of an explorer <code>p</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.copy-Tuple{AbstractExplorer}" href="#Base.copy-Tuple{AbstractExplorer}"><code>Base.copy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The internal state is also copied</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_prob-Tuple{AbstractExplorer,Any}" href="#ReinforcementLearningBase.get_prob-Tuple{AbstractExplorer,Any}"><code>ReinforcementLearningBase.get_prob</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_prob(p::AbstractExplorer, x) -&gt; AbstractDistribution</code></pre><p>Get the action distribution given action values</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_prob-Tuple{AbstractExplorer,Any,Any}" href="#ReinforcementLearningBase.get_prob-Tuple{AbstractExplorer,Any,Any}"><code>ReinforcementLearningBase.get_prob</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_prob(p::AbstractExplorer, x, mask)</code></pre><p>Similart to <code>get_prob(p::AbstractExplorer, x)</code>, but here only the <code>mask</code>ed elements are considered.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><h2 id="EnvironmentModel-1"><a class="docs-heading-anchor" href="#EnvironmentModel-1">EnvironmentModel</a><a class="docs-heading-anchor-permalink" href="#EnvironmentModel-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractEnvironmentModel" href="#ReinforcementLearningBase.AbstractEnvironmentModel"><code>ReinforcementLearningBase.AbstractEnvironmentModel</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Describe how to model a reinforcement learning environment.</p><p>TODO: need more investigation</p><p>Ref: https://bair.berkeley.edu/blog/2019/12/12/mbpo/</p><ul><li>Analytic gradient computation</li><li>Sampling-based planning</li><li>Model-based data generation</li><li>Value-equivalence prediction</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L10">source</a></section></article><h2 id="Environment-1"><a class="docs-heading-anchor" href="#Environment-1">Environment</a><a class="docs-heading-anchor-permalink" href="#Environment-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractEnv" href="#ReinforcementLearningBase.AbstractEnv"><code>ReinforcementLearningBase.AbstractEnv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">(env::AbstractEnv)(action) = env(DEFAULT_PLAYER, action) -&gt; nothing
(env::AbstractEnv)(player, action) -&gt; nothing</code></pre><p>Super type of all reinforcement learning environments. An environments is a functional object which takes in an action and returns <code>nothing</code>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>So why don&#39;t we adopt the <code>step!</code> method like OpenAI Gym here? The reason is that the async manner will simplify a lot of things here.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.DynamicStyle" href="#ReinforcementLearningBase.DynamicStyle"><code>ReinforcementLearningBase.DynamicStyle</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">DynamicStyle(x::AbstractEnv) = SEQUENTIAL</code></pre><p>Determine whether the players can play simultaneous or not. Default value is <a href="#ReinforcementLearningBase.SEQUENTIAL"><code>SEQUENTIAL</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.SIMULTANEOUS" href="#ReinforcementLearningBase.SIMULTANEOUS"><code>ReinforcementLearningBase.SIMULTANEOUS</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Environment with the <a href="#ReinforcementLearningBase.DynamicStyle"><code>DynamicStyle</code></a> of <code>SIMULTANEOUS</code> must take in actions from some (or all) players at one time</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.SEQUENTIAL" href="#ReinforcementLearningBase.SEQUENTIAL"><code>ReinforcementLearningBase.SEQUENTIAL</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Environment with the <a href="#ReinforcementLearningBase.DynamicStyle"><code>DynamicStyle</code></a> of <code>SEQUENTIAL</code> must takes actions from different players one-by-one.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_action_space" href="#ReinforcementLearningBase.get_action_space"><code>ReinforcementLearningBase.get_action_space</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_action_space(env::AbstractEnv) -&gt; AbstractSpace</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_observation_space" href="#ReinforcementLearningBase.get_observation_space"><code>ReinforcementLearningBase.get_observation_space</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_observation_space(env::AbstractEnv) -&gt; AbstractSpace</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_current_player" href="#ReinforcementLearningBase.get_current_player"><code>ReinforcementLearningBase.get_current_player</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Return <a href="#ReinforcementLearningBase.DEFAULT_PLAYER"><code>DEFAULT_PLAYER</code></a> by default</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_num_players" href="#ReinforcementLearningBase.get_num_players"><code>ReinforcementLearningBase.get_num_players</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_num_players(env::AbstractEnv) -&gt; Int</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.render" href="#ReinforcementLearningBase.render"><code>ReinforcementLearningBase.render</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Show the environment in a user-friendly manner</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.reset!-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.reset!-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.reset!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Reset the internal state of an environment</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><p>Several meta-environments are also provided:</p><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.WrappedEnv" href="#ReinforcementLearningBase.WrappedEnv"><code>ReinforcementLearningBase.WrappedEnv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">WrappedEnv(;preprocessor, env, postprocessor=identity)</code></pre><p>The observation of the inner <code>env</code> is first transformed by the <code>preprocessor</code>. And the action is transformed by <code>postprocessor</code> and then send to the inner <code>env</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L5">source</a></section></article><h2 id="Preprocessor-1"><a class="docs-heading-anchor" href="#Preprocessor-1">Preprocessor</a><a class="docs-heading-anchor-permalink" href="#Preprocessor-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractPreprocessor" href="#ReinforcementLearningBase.AbstractPreprocessor"><code>ReinforcementLearningBase.AbstractPreprocessor</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Preprocess an observation and return a new observation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section></article><h2 id="Observation-1"><a class="docs-heading-anchor" href="#Observation-1">Observation</a><a class="docs-heading-anchor-permalink" href="#Observation-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.observe" href="#ReinforcementLearningBase.observe"><code>ReinforcementLearningBase.observe</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">observe(env::AbstractEnv) = observe(env, get_current_player(env))
observe(::AbstractEnv, player)</code></pre><p>Get an observation of the <code>env</code> from the perspective of an <code>player</code>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>This is a very deliberate decision to adopt the duck-typing here to describe an observation from an environment. By default, we assume an observation is a NamedTuple, which is the most common case. But of course it can be of any type, as long as it implemented  the necessay methods described in this section.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L13">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_legal_actions_mask" href="#ReinforcementLearningBase.get_legal_actions_mask"><code>ReinforcementLearningBase.get_legal_actions_mask</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_legal_actions_mask(x) -&gt; Bool[]</code></pre><p>Only valid for observations of <a href="#ReinforcementLearningBase.FULL_ACTION_SET"><code>FULL_ACTION_SET</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_legal_actions" href="#ReinforcementLearningBase.get_legal_actions"><code>ReinforcementLearningBase.get_legal_actions</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_legal_actions(x)</code></pre><p>Only valid for observations of <a href="#ReinforcementLearningBase.FULL_ACTION_SET"><code>FULL_ACTION_SET</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_terminal" href="#ReinforcementLearningBase.get_terminal"><code>ReinforcementLearningBase.get_terminal</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_terminal(x) -&gt; bool</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_reward" href="#ReinforcementLearningBase.get_reward"><code>ReinforcementLearningBase.get_reward</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_reward(x) -&gt; Number</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_state" href="#ReinforcementLearningBase.get_state"><code>ReinforcementLearningBase.get_state</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_state(x) -&gt; Array</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_invalid_action" href="#ReinforcementLearningBase.get_invalid_action"><code>ReinforcementLearningBase.get_invalid_action</code></a> — <span class="docstring-category">Function</span></header><section><div><p>By default <a href="#ReinforcementLearningBase.INVALID_ACTION"><code>INVALID_ACTION</code></a> is returned</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.INVALID_ACTION" href="#ReinforcementLearningBase.INVALID_ACTION"><code>ReinforcementLearningBase.INVALID_ACTION</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>The default value of invalid action for all the environments. However, one can still specify the value for a specific environment or observation.</p><p><strong>See also: <a href="#ReinforcementLearningBase.get_invalid_action"><code>get_invalid_action</code></a></strong></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.ActionStyle" href="#ReinforcementLearningBase.ActionStyle"><code>ReinforcementLearningBase.ActionStyle</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ActionStyle(x)</code></pre><p>Specify whether the observation contains a full action set or a minimal action set. By default the <a href="#ReinforcementLearningBase.MINIMAL_ACTION_SET"><code>MINIMAL_ACTION_SET</code></a> is returned.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.MINIMAL_ACTION_SET" href="#ReinforcementLearningBase.MINIMAL_ACTION_SET"><code>ReinforcementLearningBase.MINIMAL_ACTION_SET</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>All actions in the action space of the environment are legal</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.FULL_ACTION_SET" href="#ReinforcementLearningBase.FULL_ACTION_SET"><code>ReinforcementLearningBase.FULL_ACTION_SET</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>The action space of the environment may contains illegal actions</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.RTSA" href="#ReinforcementLearningBase.RTSA"><code>ReinforcementLearningBase.RTSA</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>An alias of <code>(:reward, :terminal, :state, :action)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.SARTSA" href="#ReinforcementLearningBase.SARTSA"><code>ReinforcementLearningBase.SARTSA</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>An alias of <code>(:state, :action, :reward, :terminal, :next_state, :next_action)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0">source</a></section></article><p>Some meta-observations are also provided:</p><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.StateOverriddenObs" href="#ReinforcementLearningBase.StateOverriddenObs"><code>ReinforcementLearningBase.StateOverriddenObs</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">StateOverriddenObs(;obs, state)</code></pre><p>Replace the internal state of <code>obs</code> with <code>state</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; old_obs = (reward=1.0, terminal=false, state=1)
(reward = 1.0, terminal = false, state = 1)

julia&gt; new_obs = StateOverriddenObs(;obs=old_obs, state=nothing)
StateOverriddenObs{NamedTuple{(:reward, :terminal, :state),Tuple{Float64,Bool,Int64}},Nothing}((reward = 1.0, terminal = false, state = 1), nothing)

julia&gt; get_state(new_obs) === nothing
true

julia&gt; get_reward(new_obs) === get_reward(old_obs)
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L20">source</a></section></article><h2 id="Trajectory-1"><a class="docs-heading-anchor" href="#Trajectory-1">Trajectory</a><a class="docs-heading-anchor-permalink" href="#Trajectory-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractTrajectory" href="#ReinforcementLearningBase.AbstractTrajectory"><code>ReinforcementLearningBase.AbstractTrajectory</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">AbstractTrajectory{names,types} &lt;: AbstractArray{NamedTuple{names,types},1}</code></pre><p>A trajectory is used to record some useful information during the interactions between agents and environments.</p><p><strong>Parameters</strong></p><ul><li><code>names</code>::<code>NTuple{Symbol}</code>, indicate what fields to be recorded.</li><li><code>types</code>::<code>Tuple{DataType...}</code>, the datatypes of <code>names</code>.</li></ul><p>The length of <code>names</code> and <code>types</code> must match.</p><p>Required Methods:</p><ul><li><a href="#ReinforcementLearningBase.get_trace"><code>get_trace</code></a></li><li><code>Base.push!(t::AbstractTrajectory, kv::Pair{Symbol})</code></li><li><code>Base.pop!(t::AbstractTrajectory, s::Symbol)</code></li></ul><p>Optional Methods:</p><ul><li><code>Base.length</code></li><li><code>Base.size</code></li><li><code>Base.lastindex</code></li><li><code>Base.isempty</code></li><li><code>Base.empty!</code></li><li><code>Base.push!</code></li><li><code>Base.pop!</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_trace" href="#ReinforcementLearningBase.get_trace"><code>ReinforcementLearningBase.get_trace</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_trace(t::AbstractTrajectory, s::Symbol)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section><section><div><pre><code class="language-none">get_trace(t::AbstractTrajectory, s::NTuple{N,Symbol}) where {N}</code></pre></div></section><section><div><pre><code class="language-none">get_trace(t::AbstractTrajectory, s::Symbol...)</code></pre></div></section><section><div><pre><code class="language-none">get_trace(t::AbstractTrajectory{names}) where {names}</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.push!" href="#Base.push!"><code>Base.push!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Base.push!(t::AbstractTrajectory; kwargs...)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section><section><div><pre><code class="language-none">Base.push!(t::AbstractTrajectory, kv::Pair{Symbol})</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.pop!" href="#Base.pop!"><code>Base.pop!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Base.pop!(t::AbstractTrajectory{names}) where {names}</code></pre><p><code>pop!</code> out one element of each trace in <code>t</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section><section><div><pre><code class="language-none">Base.pop!(t::AbstractTrajectory, s::Symbol...)</code></pre><p><code>pop!</code> out one element of the traces specified in <code>s</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section><section><div><pre><code class="language-none">Base.pop!(t::AbstractTrajectory, s::Symbol)</code></pre><p><code>pop!</code> out one element of the trace <code>s</code> in <code>t</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L4">source</a></section></article><h2 id="Space-1"><a class="docs-heading-anchor" href="#Space-1">Space</a><a class="docs-heading-anchor-permalink" href="#Space-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractSpace" href="#ReinforcementLearningBase.AbstractSpace"><code>ReinforcementLearningBase.AbstractSpace</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Describe the span of observations and actions. Usually the following methods are implemented:</p><ul><li><code>Base.length</code></li><li><code>Base.in</code></li><li><code>Random.rand</code></li><li><code>Base.eltype</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/2d5741174ce3e6a394010d2e470e4269ca54607f/base/#L0-L8">source</a></section></article><p>Some typical implementations of <a href="#ReinforcementLearningBase.AbstractSpace"><code>AbstractSpace</code></a> are also included in the <a href="#ReinforcementLearningBase.RLBase"><code>RLBase</code></a>.</p><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.EmptySpace" href="#ReinforcementLearningBase.EmptySpace"><code>ReinforcementLearningBase.EmptySpace</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">EmptySpace()</code></pre><p>There&#39;s <code>nothing</code> in the <code>EmptySpace</code>!</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.DiscreteSpace" href="#ReinforcementLearningBase.DiscreteSpace"><code>ReinforcementLearningBase.DiscreteSpace</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">DiscreteSpace(span)</code></pre><p>The <code>span</code> can be of any iterators.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; s = DiscreteSpace([1,2,3])
DiscreteSpace{Array{Int64,1}}([1, 2, 3])

julia&gt; 0 ∉ s
true

julia&gt; 2 ∈ s
true

julia&gt; s = DiscreteSpace(Set([:a, :c, :a, :b]))
DiscreteSpace{Set{Symbol}}(Set(Symbol[:a, :b, :c]))

julia&gt; s = DiscreteSpace(3)
DiscreteSpace{UnitRange{Int64}}(1:3)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.MultiDiscreteSpace" href="#ReinforcementLearningBase.MultiDiscreteSpace"><code>ReinforcementLearningBase.MultiDiscreteSpace</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MultiDiscreteSpace(low::T, high::T) where {T&lt;:AbstractArray}</code></pre><p>Similar to <a href="#ReinforcementLearningBase.DiscreteSpace"><code>DiscreteSpace</code></a>, but scaled to multi-dimension.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.ContinuousSpace" href="#ReinforcementLearningBase.ContinuousSpace"><code>ReinforcementLearningBase.ContinuousSpace</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ContinuousSpace(low, high)</code></pre><p>Similar to <a href="#ReinforcementLearningBase.DiscreteSpace"><code>DiscreteSpace</code></a>, but the span is continuous.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.MultiContinuousSpace" href="#ReinforcementLearningBase.MultiContinuousSpace"><code>ReinforcementLearningBase.MultiContinuousSpace</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MultiContinuousSpace(low, high)</code></pre><p>Similar to <a href="#ReinforcementLearningBase.ContinuousSpace"><code>ContinuousSpace</code></a>, but scaled to multi-dimension.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.TupleSpace" href="#ReinforcementLearningBase.TupleSpace"><code>ReinforcementLearningBase.TupleSpace</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">TupleSpace(args::AbstractSpace...)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.DictSpace" href="#ReinforcementLearningBase.DictSpace"><code>ReinforcementLearningBase.DictSpace</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">DictSpace(ps::Pair{&lt;:Union{Symbol,AbstractString},&lt;:AbstractSpace}...)</code></pre></div></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../a_quick_example/">« A Quick Example</a><a class="docs-footer-nextpage" href="../rl_core/">RLCore »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 8 May 2020 15:18">Friday 8 May 2020</span>. Using Julia version 1.3.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
