<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>RLBase · ReinforcementLearning.jl</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-149861753-1', 'auto');
ga('send', 'pageview', {'page': location.pathname + location.search + location.hash});
</script><link rel="canonical" href="https://juliareinforcementlearning.github.io/ReinforcementLearning.jl/latest/rl_base/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../assets/custom.css" rel="stylesheet" type="text/css"/><link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" rel="stylesheet" type="text/css"/></head><body><div id="top" class="navbar-wrapper">
<nav class="navbar navbar-expand-lg  navbar-dark fixed-top" style="background-color: #1fd1f9; background-image: linear-gradient(315deg, #1fd1f9 0%, #b621fe 74%); " id="mainNav">
  <div class="container-md">
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarTogglerDemo01" aria-controls="navbarTogglerDemo01" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>
  <div class="collapse navbar-collapse" id="navbarTogglerDemo01">
    <span class="navbar-brand">
        <a class="navbar-brand" href="/">
          <!-- <img src="/assets/site/logo.svg" width="30" height="30" alt="logo" loading="lazy"> -->
          JuliaReinforcementLearning
        </a>
    </span>

    <ul class="navbar-nav ml-auto">
        <li class="nav-item">
        <a class="nav-link" href="/get_started/">Get Started</a>
        </li>
        <li class="nav-item">
        <a class="nav-link" href="/guide/">Guide</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/contribute/">Contribute</a>
        </li>
        <li class="nav-item">
        <a class="nav-link" href="/blog/">Blog</a>
        </li>
        <li class="nav-item">
        <a class="nav-link" href="https://JuliaReinforcementLearning.github.io/ReinforcementLearning.jl/latest/">Doc</a>
        </li>
        <li class="nav-item">
        <a class="nav-link" href="https://github.com/JuliaReinforcementLearning">Github</a>
        </li>
    </ul>
  </div>
</nav>
</div>
<div class="documenter-wrapper" id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="ReinforcementLearning.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">ReinforcementLearning.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Manual</span><ul><li class="is-active"><a class="tocitem" href>RLBase</a></li><li><a class="tocitem" href="../rl_core/">RLCore</a></li><li><a class="tocitem" href="../rl_envs/">RLEnvs</a></li><li><a class="tocitem" href="../rl_zoo/">RLZoo</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href>RLBase</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>RLBase</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/master/docs/src/rl_base.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="ReinforcementLearningBase.jl"><a class="docs-heading-anchor" href="#ReinforcementLearningBase.jl">ReinforcementLearningBase.jl</a><a id="ReinforcementLearningBase.jl-1"></a><a class="docs-heading-anchor-permalink" href="#ReinforcementLearningBase.jl" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.RLBase" href="#ReinforcementLearningBase.RLBase"><code>ReinforcementLearningBase.RLBase</code></a> — <span class="docstring-category">Module</span></header><section><div><p><a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningBase.jl">ReinforcementLearningBase.jl</a> (<strong>RLBase</strong>) provides some common constants, traits, abstractions and interfaces in developing reinforcement learning algorithms in  Julia. From the concept level, they can be organized in the following parts:</p><ul><li><a href="@ref">Policy</a></li><li><a href="@ref">EnvironmentModel</a></li><li><a href="@ref">Environment</a><ul><li><a href="@ref">Traits for Environment</a></li></ul></li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.CONSTANT_SUM" href="#ReinforcementLearningBase.CONSTANT_SUM"><code>ReinforcementLearningBase.CONSTANT_SUM</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Rewards of all players sum to a constant</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.DETERMINISTIC" href="#ReinforcementLearningBase.DETERMINISTIC"><code>ReinforcementLearningBase.DETERMINISTIC</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>No chance player in the environment. And the game is deterministic.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.EXPLICIT_STOCHASTIC" href="#ReinforcementLearningBase.EXPLICIT_STOCHASTIC"><code>ReinforcementLearningBase.EXPLICIT_STOCHASTIC</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Environment contains chance player and the probability is known.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.FULL_ACTION_SET" href="#ReinforcementLearningBase.FULL_ACTION_SET"><code>ReinforcementLearningBase.FULL_ACTION_SET</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>The action space of the environment may contains illegal actions</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.GENERAL_SUM" href="#ReinforcementLearningBase.GENERAL_SUM"><code>ReinforcementLearningBase.GENERAL_SUM</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Total rewards of all players may be different in each step</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.IDENTICAL_REWARD" href="#ReinforcementLearningBase.IDENTICAL_REWARD"><code>ReinforcementLearningBase.IDENTICAL_REWARD</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Every player gets the same reward</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.IMPERFECT_INFORMATION" href="#ReinforcementLearningBase.IMPERFECT_INFORMATION"><code>ReinforcementLearningBase.IMPERFECT_INFORMATION</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>The inner state of some players&#39; observations may be different</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.MINIMAL_ACTION_SET" href="#ReinforcementLearningBase.MINIMAL_ACTION_SET"><code>ReinforcementLearningBase.MINIMAL_ACTION_SET</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>All actions in the action space of the environment are legal</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.PERFECT_INFORMATION" href="#ReinforcementLearningBase.PERFECT_INFORMATION"><code>ReinforcementLearningBase.PERFECT_INFORMATION</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>All players observe the same state</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.SAMPLED_STOCHASTIC" href="#ReinforcementLearningBase.SAMPLED_STOCHASTIC"><code>ReinforcementLearningBase.SAMPLED_STOCHASTIC</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Environment contains chance player and the probability is unknown. Usually only a dummy action is allowed in this case.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.SEQUENTIAL" href="#ReinforcementLearningBase.SEQUENTIAL"><code>ReinforcementLearningBase.SEQUENTIAL</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Environment with the <a href="#ReinforcementLearningBase.DynamicStyle-Tuple{AbstractEnv}"><code>DynamicStyle</code></a> of <code>SEQUENTIAL</code> must takes actions from different players one-by-one.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.SIMULTANEOUS" href="#ReinforcementLearningBase.SIMULTANEOUS"><code>ReinforcementLearningBase.SIMULTANEOUS</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Environment with the <a href="#ReinforcementLearningBase.DynamicStyle-Tuple{AbstractEnv}"><code>DynamicStyle</code></a> of <code>SIMULTANEOUS</code> must take in actions from some (or all) players at one time</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.STEP_REWARD" href="#ReinforcementLearningBase.STEP_REWARD"><code>ReinforcementLearningBase.STEP_REWARD</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>We can get reward after each step</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.STOCHASTIC" href="#ReinforcementLearningBase.STOCHASTIC"><code>ReinforcementLearningBase.STOCHASTIC</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>No chance player in the environment. And the game is stochastic.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.TERMINAL_REWARD" href="#ReinforcementLearningBase.TERMINAL_REWARD"><code>ReinforcementLearningBase.TERMINAL_REWARD</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Only get reward at the end of environment</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.ZERO_SUM" href="#ReinforcementLearningBase.ZERO_SUM"><code>ReinforcementLearningBase.ZERO_SUM</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Rewards of all players sum to 0</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractEnv" href="#ReinforcementLearningBase.AbstractEnv"><code>ReinforcementLearningBase.AbstractEnv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">(env::AbstractEnv)(action) = env(action, get_current_player(env)) -&gt; env
(env::AbstractEnv)(action, player) -&gt; env</code></pre><p>Super type of all reinforcement learning environments.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractEnvironmentModel" href="#ReinforcementLearningBase.AbstractEnvironmentModel"><code>ReinforcementLearningBase.AbstractEnvironmentModel</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Describe how to model a reinforcement learning environment. TODO: need more investigation Ref: https://bair.berkeley.edu/blog/2019/12/12/mbpo/</p><ul><li>Analytic gradient computation</li><li>Sampling-based planning</li><li>Model-based data generation</li><li>Value-equivalence prediction</li></ul><p><a href="https://arxiv.org/pdf/2006.16712.pdf">Model-based Reinforcement Learning: A Survey.</a> <a href="https://sites.google.com/view/mbrl-tutorial">Tutorial on Model-Based Methods in Reinforcement Learning</a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractPolicy" href="#ReinforcementLearningBase.AbstractPolicy"><code>ReinforcementLearningBase.AbstractPolicy</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">(π::AbstractPolicy)(env) -&gt; action</code></pre><p>Policy is the most basic concept in reinforcement learning. A policy is a functional object which takes in an environemnt and generate an action.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.AbstractSpace" href="#ReinforcementLearningBase.AbstractSpace"><code>ReinforcementLearningBase.AbstractSpace</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Describe the span of states and actions. Usually the following methods are implemented:</p><ul><li><code>Base.length</code></li><li><code>Base.in</code></li><li><code>Random.rand</code></li><li><code>Base.eltype</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.ContinuousSpace-Tuple{Any,Any}" href="#ReinforcementLearningBase.ContinuousSpace-Tuple{Any,Any}"><code>ReinforcementLearningBase.ContinuousSpace</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ContinuousSpace(low, high)</code></pre><p>Similar to <a href="#ReinforcementLearningBase.DiscreteSpace"><code>DiscreteSpace</code></a>, but the span is continuous.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.DictSpace-Tuple{Vararg{Pair{#s13,#s12} where #s12&lt;:AbstractSpace where #s13&lt;:Union{AbstractString, Symbol},N} where N}" href="#ReinforcementLearningBase.DictSpace-Tuple{Vararg{Pair{#s13,#s12} where #s12&lt;:AbstractSpace where #s13&lt;:Union{AbstractString, Symbol},N} where N}"><code>ReinforcementLearningBase.DictSpace</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">DictSpace(ps::Pair{&lt;:Union{Symbol,AbstractString},&lt;:AbstractSpace}...)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.DiscreteSpace" href="#ReinforcementLearningBase.DiscreteSpace"><code>ReinforcementLearningBase.DiscreteSpace</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">DiscreteSpace(span)</code></pre><p>The <code>span</code> can be of any iterators.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; s = DiscreteSpace([1,2,3])
DiscreteSpace{Array{Int64,1}}([1, 2, 3])

julia&gt; 0 ∉ s
true

julia&gt; 2 ∈ s
true

julia&gt; s = DiscreteSpace(Set([:a, :c, :a, :b]))
DiscreteSpace{Set{Symbol}}(Set(Symbol[:a, :b, :c]))

julia&gt; s = DiscreteSpace(3)
DiscreteSpace{UnitRange{Int64}}(1:3)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.DiscreteSpace-Tuple{Any,Any}" href="#ReinforcementLearningBase.DiscreteSpace-Tuple{Any,Any}"><code>ReinforcementLearningBase.DiscreteSpace</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">DiscreteSpace(low, high)</code></pre><p>Create a <code>DiscreteSpace</code> with span of <code>low:high</code></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.DiscreteSpace-Union{Tuple{T}, Tuple{T}} where T&lt;:Integer" href="#ReinforcementLearningBase.DiscreteSpace-Union{Tuple{T}, Tuple{T}} where T&lt;:Integer"><code>ReinforcementLearningBase.DiscreteSpace</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">DiscreteSpace(high::T)</code></pre><p>Create a <code>DiscreteSpace</code> with span of <code>1:high</code></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.EmptySpace" href="#ReinforcementLearningBase.EmptySpace"><code>ReinforcementLearningBase.EmptySpace</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">EmptySpace()</code></pre><p>There&#39;s <code>nothing</code> in the <code>EmptySpace</code>!</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.MultiContinuousSpace-Tuple{Any,Any}" href="#ReinforcementLearningBase.MultiContinuousSpace-Tuple{Any,Any}"><code>ReinforcementLearningBase.MultiContinuousSpace</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">MultiContinuousSpace(low, high)</code></pre><p>Similar to <a href="#ReinforcementLearningBase.ContinuousSpace-Tuple{Any,Any}"><code>ContinuousSpace</code></a>, but scaled to multi-dimension.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.MultiDiscreteSpace" href="#ReinforcementLearningBase.MultiDiscreteSpace"><code>ReinforcementLearningBase.MultiDiscreteSpace</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MultiDiscreteSpace(low::T, high::T) where {T&lt;:AbstractArray}</code></pre><p>Similar to <a href="#ReinforcementLearningBase.DiscreteSpace"><code>DiscreteSpace</code></a>, but scaled to multi-dimension.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.MultiDiscreteSpace-Union{Tuple{T}, Tuple{T}} where T&lt;:AbstractArray" href="#ReinforcementLearningBase.MultiDiscreteSpace-Union{Tuple{T}, Tuple{T}} where T&lt;:AbstractArray"><code>ReinforcementLearningBase.MultiDiscreteSpace</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">MultiDiscreteSpace(high::T) where {T&lt;:AbstractArray}</code></pre><p>The <code>low</code> will fall back to <code>ones(eltype(T), size(high))</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.MultiThreadEnv" href="#ReinforcementLearningBase.MultiThreadEnv"><code>ReinforcementLearningBase.MultiThreadEnv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MultiThreadEnv(envs::Vector{&lt;:AbstractEnv})</code></pre><p>Wrap multiple environments into one environment. Each environment will run in parallel by leveraging <code>Threads.@spawn</code>. So remember to set the environment variable <code>JULIA_NUM_THREADS</code>!</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.RandomPolicy" href="#ReinforcementLearningBase.RandomPolicy"><code>ReinforcementLearningBase.RandomPolicy</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">RandomPolicy(action_space, rng=Random.GLOBAL_RNG)</code></pre><p>Construct a random policy with actions in <code>action_space</code>. If <code>action_space</code> is <code>nothing</code> then the <code>legal_actions</code> at runtime will be used to randomly sample a valid action.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.RandomPolicy-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.RandomPolicy-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.RandomPolicy</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">RandomPolicy(env::AbstractEnv; rng=Random.GLOBAL_RNG)</code></pre><p>If <code>env</code> is of <a href="#ReinforcementLearningBase.FULL_ACTION_SET"><code>FULL_ACTION_SET</code></a>, then action is randomly chosen at runtime in <code>get_actions(env)</code>. Otherwise, the <code>env</code> is supposed to be of <a href="#ReinforcementLearningBase.MINIMAL_ACTION_SET"><code>MINIMAL_ACTION_SET</code></a>. The <code>get_actions(env)</code> is supposed to be static and will only be used to initialize the random policy for once.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.StateCachedEnv" href="#ReinforcementLearningBase.StateCachedEnv"><code>ReinforcementLearningBase.StateCachedEnv</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Cache the state so that <code>get_state(env)</code> will always return the same result before the next interaction with <code>env</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.copy-Tuple{AbstractEnv}" href="#Base.copy-Tuple{AbstractEnv}"><code>Base.copy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Make an independent copy of <code>env</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.run-Tuple{Any,AbstractEnv}" href="#Base.run-Tuple{Any,AbstractEnv}"><code>Base.run</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">run(π, env::AbstractEnv)</code></pre><p>Run the policy <code>π</code> in <code>env</code> until the end.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Random.seed!-Tuple{AbstractEnv,Any}" href="#Random.seed!-Tuple{AbstractEnv,Any}"><code>Random.seed!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Set the seed of internal rng</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.ActionStyle-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.ActionStyle-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.ActionStyle</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ActionStyle(env::AbstractEnv)</code></pre><p>Specify whether the current state of <code>env</code> contains a full action set or a minimal action set. By default the <a href="#ReinforcementLearningBase.MINIMAL_ACTION_SET"><code>MINIMAL_ACTION_SET</code></a> is returned.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.ChanceStyle-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.ChanceStyle-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.ChanceStyle</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ChanceStyle(env) = DETERMINISTIC</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.DynamicStyle-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.DynamicStyle-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.DynamicStyle</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">DynamicStyle(env::AbstractEnv) = SEQUENTIAL</code></pre><p>Determine whether the players can play simultaneously or not. Default value is <a href="#ReinforcementLearningBase.SEQUENTIAL"><code>SEQUENTIAL</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.InformationStyle-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.InformationStyle-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.InformationStyle</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">InformationStyle(env) = PERFECT_INFORMATION</code></pre><p>Specify whether the <code>env</code> is <a href="@ref">PERFECT_INFORMATION</a> or <a href="@ref">IMPERFECT_INFORMATION</a>. Return <a href="@ref">PERFECT_INFORMATION</a> by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.NumAgentStyle-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.NumAgentStyle-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.NumAgentStyle</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">NumAgentStyle(env)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.RewardStyle-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.RewardStyle-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.RewardStyle</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Specify whether we can get reward after each step or only at the end of an game. Possible values are <a href="@ref">STEP_REWARD</a> or <a href="@ref">TERMINAL_REWARD</a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.UtilityStyle-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.UtilityStyle-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.UtilityStyle</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">UtilityStyle(env::AbstractEnv)</code></pre><p>Specify the utility style in multi-agent environments. Possible values are:</p><ul><li><a href="@ref">ZERO_SUM</a></li><li><a href="@ref">CONSTANT_SUM</a></li><li><a href="@ref">GENERAL_SUM</a></li><li><a href="@ref">IDENTICAL_REWARD</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.child-Tuple{AbstractEnv,Any}" href="#ReinforcementLearningBase.child-Tuple{AbstractEnv,Any}"><code>ReinforcementLearningBase.child</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">child(env::AbstractEnv, action)</code></pre><p>Treat the <code>env</code> as a game tree. Create an independent child after applying <code>action</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_actions" href="#ReinforcementLearningBase.get_actions"><code>ReinforcementLearningBase.get_actions</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_actions(env, player=get_current_player(env))</code></pre><p>Get all available actions from environment. See also: <a href="#ReinforcementLearningBase.get_legal_actions"><code>get_legal_actions</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_chance_player-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.get_chance_player-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.get_chance_player</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_chance_player(env)</code></pre><p>Only valid for environments with a chance player.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_current_player-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.get_current_player-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.get_current_player</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_current_player(env)</code></pre><p>Return the next player to take action. For <a href="https://en.wikipedia.org/wiki/Extensive-form_game">Extensive Form Games</a>, A <em>chance player</em> may be returned. (See also <a href="#ReinforcementLearningBase.get_chance_player-Tuple{AbstractEnv}"><code>get_chance_player</code></a>) For <a href="@ref">SIMULTANEOUS</a> environments, a <em>simultaneous player</em> may be returned. (See also <a href="#ReinforcementLearningBase.get_simultaneouse_player-Tuple{Any}"><code>get_simultaneouse_player</code></a>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_history" href="#ReinforcementLearningBase.get_history"><code>ReinforcementLearningBase.get_history</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Get all actions in each ply</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_legal_actions" href="#ReinforcementLearningBase.get_legal_actions"><code>ReinforcementLearningBase.get_legal_actions</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_legal_actions(env, player=get_current_player(env))</code></pre><p>Only valid for environments of <a href="#ReinforcementLearningBase.FULL_ACTION_SET"><code>FULL_ACTION_SET</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_legal_actions_mask" href="#ReinforcementLearningBase.get_legal_actions_mask"><code>ReinforcementLearningBase.get_legal_actions_mask</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_legal_actions_mask(env, player=get_current_player(env)) -&gt; AbstractArray{Bool}</code></pre><p>Required for environments of <a href="#ReinforcementLearningBase.FULL_ACTION_SET"><code>FULL_ACTION_SET</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_priority-Tuple{AbstractPolicy,Any}" href="#ReinforcementLearningBase.get_priority-Tuple{AbstractPolicy,Any}"><code>ReinforcementLearningBase.get_priority</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_priority(π::AbstractPolicy, experience)</code></pre><p>Usually used in offline policies.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_prob" href="#ReinforcementLearningBase.get_prob"><code>ReinforcementLearningBase.get_prob</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_prob(env, player=get_chance_player(env))</code></pre><p>Only valid for environments of <a href="#ReinforcementLearningBase.EXPLICIT_STOCHASTIC"><code>EXPLICIT_STOCHASTIC</code></a> style. Here <code>player</code> must be a chance player.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_prob-Tuple{AbstractPolicy,Any,Any}" href="#ReinforcementLearningBase.get_prob-Tuple{AbstractPolicy,Any,Any}"><code>ReinforcementLearningBase.get_prob</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_prob(π::AbstractPolicy, env, action)</code></pre><p>Only valid for environments with discrete action space.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_prob-Tuple{AbstractPolicy,Any}" href="#ReinforcementLearningBase.get_prob-Tuple{AbstractPolicy,Any}"><code>ReinforcementLearningBase.get_prob</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_prob(π::AbstractPolicy, env)</code></pre><p>Get the probability distribution of actions based on policy <code>π</code> given an <code>env</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_reward" href="#ReinforcementLearningBase.get_reward"><code>ReinforcementLearningBase.get_reward</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_reward(env, player=get_current_player(env))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_simultaneouse_player-Tuple{Any}" href="#ReinforcementLearningBase.get_simultaneouse_player-Tuple{Any}"><code>ReinforcementLearningBase.get_simultaneouse_player</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_simultaneouse_player(env)</code></pre><p>Only valid for environments of <a href="#ReinforcementLearningBase.SIMULTANEOUS"><code>SIMULTANEOUS</code></a> style.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_spectator_player-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.get_spectator_player-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.get_spectator_player</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_spectator_player(env)</code></pre><p>Used in imperfect multi-agent environments.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_state" href="#ReinforcementLearningBase.get_state"><code>ReinforcementLearningBase.get_state</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_state([t::Type], env, player=get_current_player(env)) -&gt; state</code></pre><p>The state can be of any type. However, most neural network based algorithms assume it&#39;s an <code>AbstractArray</code>. For environments with many different states provided (inner state, information state, etc), users need to provide <code>t::Type</code> to declare which kind of state they want.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.get_terminal" href="#ReinforcementLearningBase.get_terminal"><code>ReinforcementLearningBase.get_terminal</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_terminal(env, player=get_current_player(env))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.reset!-Tuple{AbstractEnv}" href="#ReinforcementLearningBase.reset!-Tuple{AbstractEnv}"><code>ReinforcementLearningBase.reset!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Reset the internal state of an environment</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearningBase.update!-Tuple{AbstractPolicy,Any}" href="#ReinforcementLearningBase.update!-Tuple{AbstractPolicy,Any}"><code>ReinforcementLearningBase.update!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">update!(π::AbstractPolicy, experience)</code></pre><p>Update the policy <code>π</code> with online/offline experience.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/#L0-L4">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../rl_core/">RLCore »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 5 August 2020 08:22">Wednesday 5 August 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
