<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Action Selectors · ReinforcementLearning.jl</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-149861753-1', 'auto');
ga('send', 'pageview', {'page': location.pathname + location.search + location.hash});
</script><link rel="canonical" href="https://juliareinforcementlearning.github.io/ReinforcementLearning.jl/latest/components/action_selectors/index.html"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/custom.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="ReinforcementLearning.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">ReinforcementLearning.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../a_quick_example/">A Quick Example</a></li><li><a class="tocitem" href="../../overview/">Overview</a></li><li><span class="tocitem">Manual</span><ul><li><input class="collapse-toggle" id="menuitem-4-1" type="checkbox" checked/><label class="tocitem" for="menuitem-4-1"><span class="docs-label">Components</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../agents/">Agents</a></li><li><a class="tocitem" href="../environments/">Environments</a></li><li><a class="tocitem" href="../buffers/">Buffers</a></li><li><a class="tocitem" href="../policies/">Policies</a></li><li><a class="tocitem" href="../learners/">Learners</a></li><li><a class="tocitem" href="../approximators/">Approximators</a></li><li class="is-active"><a class="tocitem" href>Action Selectors</a></li><li><a class="tocitem" href="../environment_models/">Environment Models</a></li></ul></li><li><a class="tocitem" href="../../core/">Core</a></li><li><a class="tocitem" href="../../utils/">Utils</a></li></ul></li><li><a class="tocitem" href="../../tips_for_developers/">Tips for Developers</a></li><li><span class="tocitem">Experiments</span><ul><li><a class="tocitem" href="../../experiments/atari_dqn/">Play Atari Games with DQN</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li><a class="is-disabled">Components</a></li><li class="is-active"><a href>Action Selectors</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Action Selectors</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/master/docs/src/components/action_selectors.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Action-Selectors-1"><a class="docs-heading-anchor" href="#Action-Selectors-1">Action Selectors</a><a class="docs-heading-anchor-permalink" href="#Action-Selectors-1" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearning.AbstractDiscreteActionSelector" href="#ReinforcementLearning.AbstractDiscreteActionSelector"><code>ReinforcementLearning.AbstractDiscreteActionSelector</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">AbstractDiscreteActionSelector</code></pre><p>Generate an action given the estimated value of different actions.</p><table><tr><th style="text-align: left">Required Methods</th><th style="text-align: left">Brief Description</th></tr><tr><td style="text-align: left"><code>selector(values; kwargs...)</code></td><td style="text-align: left"><code>selector</code>, an instance of <code>AbstractDiscreteActionSelector</code>, must be a callable object which takes in an estimation of all discrete actions and returns an action.</td></tr></table></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/aae24d5e107939048440561e912c73ca0e8519f9/src/components/action_selectors/abstract_action_selector.jl#L10-L18">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearning.AlternateSelector" href="#ReinforcementLearning.AlternateSelector"><code>ReinforcementLearning.AlternateSelector</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">AlternateSelector(n::Int)</code></pre><p>Used to ensure that all actions are selected alternatively.</p><p><strong>Fields</strong></p><ul><li><code>n::Int</code>: means the optional actions are <code>1:n</code>.</li><li><code>step::Int=0</code>: record the number of times that the selector is applied.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/46ce4d79337bdd257ee2e3d2f4bb1c55ff0a5030/base/#L0-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearning.EpsilonGreedySelector" href="#ReinforcementLearning.EpsilonGreedySelector"><code>ReinforcementLearning.EpsilonGreedySelector</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">EpsilonGreedySelector{T}(;kwargs...)</code></pre><blockquote><p>Epsilon-greedy strategy: The best lever is selected for a proportion <code>1 - epsilon</code> of the trials, and a lever is selected at random (with uniform probability) for a proportion epsilon . <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed_bandit</a></p></blockquote><p>Two kinds of epsilon-decreasing strategy are implmented here (<code>linear</code> and <code>exp</code>).</p><blockquote><p>Epsilon-decreasing strategy: Similar to the epsilon-greedy strategy, except that the value of epsilon decreases as the experiment progresses, resulting in highly explorative behaviour at the start and highly exploitative behaviour at the finish.  - <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed_bandit</a></p></blockquote><p><strong>Keywords</strong></p><ul><li><code>T::Symbol</code>: defines how to calculate the epsilon in the warmup steps. Supported values are <code>linear</code> and <code>exp</code>.</li><li><code>step::Int = 1</code>: record the current step.</li><li><code>ϵ_init::Float64 = 1.0</code>: initial epsilon.</li><li><code>warmup_steps::Int=0</code>: the number of steps to use <code>ϵ_init</code>.</li><li><code>decay_steps::Int=0</code>: the number of steps for epsilon to decay from <code>ϵ_init</code> to <code>ϵ_stable</code>.</li><li><code>ϵ_stable::Float64</code>: the epsilon after <code>warmup_steps + decay_steps</code>.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia">s = EpsilonGreedySelector{:linear}(ϵ_init=0.9, ϵ_stable=0.1, warmup_steps=100, decay_steps=100)
plot([RL.get_ϵ(s, i) for i in 1:500], label=&quot;linear epsilon&quot;)</code></pre><p><img src="../../assets/img/linear_epsilon_greedy_selector.png" alt/></p><pre><code class="language-julia">s = EpsilonGreedySelector{:exp}(ϵ_init=0.9, ϵ_stable=0.1, warmup_steps=100, decay_steps=100)
plot([RL.get_ϵ(s, i) for i in 1:500], label=&quot;exp epsilon&quot;)</code></pre><p><img src="../../assets/img/exp_epsilon_greedy_selector.png" alt/></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/46ce4d79337bdd257ee2e3d2f4bb1c55ff0a5030/base/#L0-L31">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearning.UCBSelector" href="#ReinforcementLearning.UCBSelector"><code>ReinforcementLearning.UCBSelector</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">UCBSelector(na; c=2.0, ϵ=1e-10)</code></pre><p><strong>Arguments</strong></p><ul><li><code>na</code> is the number of actions used to create a internal counter.</li><li><code>t</code> is used to store current time step.</li><li><code>c</code> is used to control the degree of exploration.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/aae24d5e107939048440561e912c73ca0e8519f9/src/components/action_selectors/ucb_selector.jl#L5-L12">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ReinforcementLearning.WeightedSelector" href="#ReinforcementLearning.WeightedSelector"><code>ReinforcementLearning.WeightedSelector</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">WeightedSelector(is_normalized::Bool)</code></pre><p><code>is_normalized</code> is used to indicating if the feeded action values are alrady normalized to have a sum of <code>1.0</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/aae24d5e107939048440561e912c73ca0e8519f9/src/components/action_selectors/weighted_selector.jl#L5-L10">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../approximators/">« Approximators</a><a class="docs-footer-nextpage" href="../environment_models/">Environment Models »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 7 December 2019 12:47">Saturday 7 December 2019</span>. Using Julia version 1.3.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
