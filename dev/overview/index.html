<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Overview · ReinforcementLearning.jl</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-149861753-1', 'auto');
ga('send', 'pageview', {'page': location.pathname + location.search + location.hash});
</script><link rel="canonical" href="https://juliareinforcementlearning.github.io/ReinforcementLearning.jl/latest/overview/index.html"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../assets/custom.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="ReinforcementLearning.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">ReinforcementLearning.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Overview</a><ul class="internal"><li><a class="tocitem" href="#Key-Concepts-1"><span>Key Concepts</span></a></li></ul></li><li><a class="tocitem" href="../a_quick_example/">A Quick Example</a></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../rl_base/">RLBase</a></li><li><a class="tocitem" href="../rl_core/">RLCore</a></li><li><a class="tocitem" href="../rl_envs/">RLEnvs</a></li><li><a class="tocitem" href="../rl_zoo/">RLZoo</a></li></ul></li><li><a class="tocitem" href="../tips_for_developers/">Tips for Developers</a></li><li><span class="tocitem">Experiments</span><ul><li><a class="tocitem" href="../experiments/atari_dqn/">Play Atari Games with DQN</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Overview</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Overview</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/master/docs/src/overview.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Overview-1"><a class="docs-heading-anchor" href="#Overview-1">Overview</a><a class="docs-heading-anchor-permalink" href="#Overview-1" title="Permalink"></a></h1><p>Before diving into details, let&#39;s review some basic concepts in <strong>RL(Reinforcement Learning)</strong> first. Then we&#39;ll gradually introduce the relationship between those concepts and our implementations in this package.</p><h2 id="Key-Concepts-1"><a class="docs-heading-anchor" href="#Key-Concepts-1">Key Concepts</a><a class="docs-heading-anchor-permalink" href="#Key-Concepts-1" title="Permalink"></a></h2><h3 id="Agent-and-Environment-1"><a class="docs-heading-anchor" href="#Agent-and-Environment-1">Agent and Environment</a><a class="docs-heading-anchor-permalink" href="#Agent-and-Environment-1" title="Permalink"></a></h3><img src="/assets/img/agent_env_relation.png" width="640px"><p>Generally speaking, RL is to learn how to take actions so as to maximize a numerical reward. Two core concepts in RL are <strong>Agent</strong> and <strong>Environment</strong>. In each step, the agent is provided with the observation of the environment and is required to take an action. Then the environment consumes that action and transites to another state, providing a numerical reward in the meantime.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Sometimes people are confused about the concept of <strong>state</strong> and <strong>observation</strong> (see also the discussion <a href="https://ai.stackexchange.com/questions/5970/what-is-the-difference-between-an-observation-and-a-state-in-reinforcement-learn">here</a>). In this package, we treat all the information we can get from the perspective of an agent in each step as an <strong>observation</strong>, including <em>state</em>, <em>reward</em> and some other extra <em>info</em>.</p><p>Here we adopt the idea of <a href="https://en.wikipedia.org/wiki/Duck_typing">Duck typing</a> to describe the observation from an environment. See <a href="@ref">Environments</a> for more details.</p></div></div><p>In this package, <a href="@ref"><strong>Agent</strong></a> is one of the most typical subtypes of <a href="../rl_base/#ReinforcementLearningBase.AbstractAgent"><code>AbstractAgent</code></a>. And you may find different kinds of <strong>Environment</strong>s provided in <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironments.jl">ReinforcementLearningEnvironments.jl</a>. Agents and environments are required to be functional objects. So we can use the piping operator (<code>|&gt;</code>) to simulate the steps implied in the above picture: <code>env |&gt; observe |&gt; agent |&gt; env</code>. See <a href="../rl_core/#Agents-1">Agents</a> and <a href="@ref">Environments</a> for more some concrete implementations.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../a_quick_example/">A Quick Example »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 29 February 2020 06:47">Saturday 29 February 2020</span>. Using Julia version 1.3.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
